{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswahl und Training eines Modells\n",
    "Bis hierhin gekommen, haben Sie das Analyseproblem erfasst, Sie haben die Daten erhalten und untersucht, Sie haben ein Trainingsset und ein Testset erstellt und Sie haben Transformationspipelines geschrieben, um Ihre Daten zu bereinigen und automatisch für die Algorithmen des maschinellen Lernens vorzubereiten. Sie sind nun bereit, ein Modell für maschinelles Lernen auszuwählen und zu trainieren. Ab jetzt wird es auch einfacher werden, als Sie denken. Der größte Aufwand besteht bei maschinellem Lernen immer in der Vorbereitung der Daten. Zunächst bereiten wir wieder unsere Daten vor, wie in Kapitel 4 gezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datenvorbereitung aus Kapitel 4\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Datenbeschaffung / Einlesen einer csv Datei wie in Abschnitt 2 beschrieben\n",
    "def load_housing_data():\n",
    "    csv_path = os.path.join(\"datasets/housing/housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "\n",
    "    # Da die Methode nur die Werte übergeben bekommt. muss auf das Array mit Spaltennummern (rooms_ix etc.) zugegriffen werden\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "housing = load_housing_data()\n",
    "\n",
    "# Erstellung income category Attribut mit fünf Kategorien\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "\n",
    "# Basierend auf dem Kategorie-Attribut wird nun eine stratifizierte Stichprobe gezogen\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "housing = strat_train_set.drop(\"median_house_value\",axis=1)\n",
    "\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "# Erstellen eines Dataframes ohne kategorielle Attribute\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "# Klasse für die Auswahl nummerischer und kategorieller Spalten\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# Pipeline für ide Verarbeitung nummerischer Attribute\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "# Pipeline für die Verarbeitung kategorieller Attribute\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attribs)),\n",
    "    ('label_binarizer', OneHotEncoder()),\n",
    "    ])\n",
    "\n",
    "# Zusammensetzen der Teil-Pipelines\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "# Bis hierher arbeitet die pipeline noch nicht mit echten Daten. Sie verfügt nur über das Wissen über die Attribute und der \n",
    "# Transformationsfunktionen. Erst jetzt werden der Pipeline echte housing-Daten übergeben:\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lassen Sie uns nun mit einer einfachen linearen regression starten. Dafür bietet sklearn die Klasse LinearRegression an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das wars! Sie haben Ihre erste Datenanalyse mit Python erstellt. Lassen Sie uns das Modell an ein par Testdaten aus dem Trainingsdatensatz ausprobieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\t [203682.37421606 326371.39500521 204218.64541583  58685.47562356\n",
      " 194213.06476433]\n",
      "Labels:\t\t [286600.0, 340600.0, 196900.0, 46300.0, 254500.0]\n"
     ]
    }
   ],
   "source": [
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"Predictions:\\t\", lin_reg.predict(some_data_prepared))\n",
    "\n",
    "print(\"Labels:\\t\\t\", list(some_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es funktioniert. Auch wenn die Vorhersagen nicht genau und präzise sind, so stimmt die grundsätzliche Richtung. Lassen Sie uns nun die Leistungsfähigkeit des Modells messen. Dafür haben wir in Kapitel 1 das Root Mean Square Error (RMSE) Verfahren kennengelernt. Wendne Wir nun das RMSE-Verfahren auf dem ganzen Trainingsdatensatz an. Sklearn stellt dafür die Klasse **mean_squared_error** zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68376.6429545994"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, das ist besser als nichts, aber eindeutig kein tolles Ergebnis: Die Medianwerte der meisten Distrikte liegen zwischen 120.000 und 265.000 Dollar, so dass ein typischer Prognosefehler von 68.628 Dollar nicht sehr zufriedenstellend ist. Dies ist ein Beispiel für ein Modell, für das die Trainingsdaten nicht ausreichen. Wenn dies geschieht, kann es bedeuten, dass die Merkmale nicht genügend Informationen für gute Vorhersagen liefern oder dass das Modell nicht leistungsfähig genug ist. Wie wir im vorigen Kapitel gesehen haben, bestehen die Hauptmöglichkeiten zur Behebung der Ungenauigkeit darin, die Einschränkungen des Modells zu reduzieren. \n",
    "\n",
    "Sie könnten versuchen, weitere Attribute hinzuzufügen (z.B. das Logbuch der Bevölkerung), aber lassen Sie uns zuerst ein komplexeres Modell ausprobieren, um zu sehen, wie es funktioniert. Lassen Sie uns einen **Entscheidungsbaum-Regressor** trainieren. Dies ist ein leistungsfähiges Modell, das in der Lage ist, komplexe nichtlineare Beziehungen in den Daten zu finden. Der Code sollte inzwischen bekannt aussehen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt ist das Modell trainiert. Werten wir es nun aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was? Überhaupt kein Fehler? Könnte dieses Modell wirklich absolut perfekt sein? Natürlich ist es viel wahrscheinlicher, dass das Modell die Daten schlecht ausgewertet hat. Wie können Sie sicher sein?, dass es wirklich ein schlechtes Modell ist? Wie wir in Kapitel 4 gesehen haben, wollen Sie den Testsatz nicht anfassen, bevor Sie nicht bereit sind, ein Modell zu starten, von dem Sie überzeugt sind. Also müssen Sie einen Teil des Trainingssatzes für das Training und einen Teil für die Modellvalidierung verwenden.\n",
    "\n",
    "Dies kann durch die Verwendung der Scikit-Learn-Funktion zur Kreuzvalidierung geschehen. Der folgende Code führt eine **K-Fold-Kreuzvalidierung** durch: Er teilt den Trainingssatz nach dem Zufallsprinzip in 10 verschiedene Teilmengen, die als *Folds* bezeichnet werden, dann trainiert und bewertet er das Entscheidungsbaum-Modell 10 Mal, wobei er jedes Mal einen anderen *Fold* zur Bewertung auswählt und auf den anderen 9 Folds trainiert. Das Ergebnis ist ein Array mit den 10 Bewertungsergebnissen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns die Ergebnisse an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [68662.81444455 66566.25492662 71306.45872488 69075.20867824\n",
      " 71104.76073849 75332.84866504 71612.50623391 71311.06830579\n",
      " 77272.0399851  70674.06173656]\n",
      "Mean: 71291.80224391731\n",
      "Standard deviation: 2945.65758114086\n"
     ]
    }
   ],
   "source": [
    "# Funktion für die Rückgabe des Qualitätsmerkmals  Scores\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt sieht der Entscheidungsbaum nicht mehr so gut aus wie vorher. Tatsächlich scheint er schlechter als das Modell der linearen Regression zu sein! Beachten Sie, dass die Kreuzvalidierung Ihnen nicht nur eine Schätzung der Leistung Ihres Modells ermöglicht, sondern auch ein Maß dafür, wie genau diese Schätzung ist (d.h. ihre Standardabweichung). Der Entscheidungsbaum hat einen Wert von ungefähr 71.200, ± 3.000. Diese Informationen lägen Ihnen nicht vor, wenn Sie nur einen Validierungssatz verwendet hätten. Aber die Kreuzvalidierung geht auf Kosten des Modelltrainings, was nicht immer möglich ist.\n",
    "**Aufgabe 1:** Berechnen Sie die gleichen Scores für das lineare Regressionsmodell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [66877.52329047 66608.12020249 70575.91162015 74179.94793032\n",
      " 67683.3220154  71103.16844079 64782.65900243 67711.2994259\n",
      " 71080.40466615 67687.63849832]\n",
      "Mean: 68828.99950924338\n",
      "Standard deviation: 2662.7615667978857\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Entscheidungsbaum-Algorithmus ist offenbar noch schlechter als die lineare Regression. Lassen Sie uns noch ein letztes Modell ausprobieren: den **RandomForestRegressor**. RandomForest arbeitet, indem es viele Entscheidungsbäume auf zufällige Teilmengen der Attribute trainieren und dann den Druchschnitt ihrer Ergebnisse zu ermitteln. Der Aufbau eines Modells auf den Ergebnissen anderer Modelle wird als *Ensemble-Learning* bezeichnet und es ist oft eine gute Möglichkeit, ML-Algorithmen noch weiter voranzutreiben.\n",
    "**Aufgabe 2:** Erstellen Sie einen randomForestRegressor und berechnen Sie die Scores für dessen Performance. Orientieren Sie sich dabei an den oberen Beispielen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# ToDo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
