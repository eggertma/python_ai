{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning von Modellen\n",
    "Nehmen wir an, Sie haben jetzt eine Liste mit vielversprechenden Modellen in der engeren Wahl. Sie müssen sie nun noch verfeinern. Sehen wir uns einige Möglichkeiten an, wie Sie das tun können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Datenvorbereitung aus Kapitel 4\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator , TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Datenbeschaffung / Einlesen einer csv Datei wie in Abschnitt 2 beschrieben\n",
    "def load_housing_data():\n",
    "    csv_path = os.path.join(\"datasets/housing/housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, household_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "\n",
    "    # Da die Methode nur die Werte übergeben bekommt. muss auf das Array mit Spaltennummern (rooms_ix etc.) zugegriffen werden\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "housing = load_housing_data()\n",
    "\n",
    "# Erstellung income category Attribut mit fünf Kategorien\n",
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "\n",
    "# Basierend auf dem Kategorie-Attribut wird nun eine stratifizierte Stichprobe gezogen\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "housing = strat_train_set.drop(\"median_house_value\",axis=1)\n",
    "\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "# Erstellen eines Dataframes ohne kategorielle Attribute\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "# Klasse für die Auswahl nummerischer und kategorieller Spalten\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# Pipeline für ide Verarbeitung nummerischer Attribute\n",
    "num_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(num_attribs)),\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "# Pipeline für die Verarbeitung kategorieller Attribute\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(cat_attribs)),\n",
    "    ('label_binarizer', OneHotEncoder()),\n",
    "    ])\n",
    "\n",
    "# Zusammensetzen der Teil-Pipelines\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    (\"num_pipeline\", num_pipeline),\n",
    "    (\"cat_pipeline\", cat_pipeline),\n",
    "    ])\n",
    "\n",
    "# Bis hierher arbeitet die pipeline noch nicht mit echten Daten. Sie verfügt nur über das Wissen über die Attribute und der\n",
    "# Transformationsfunktionen. Erst jetzt werden der Pipeline echte housing-Daten übergeben:\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "Eine Möglichkeit ist, mit den Hyperparametern (Konfigurationsparamter der ML-Algorithmen) manuell zu spielen, bis man eine hinreichend gute Kombination von Hyperparameterwerten findet. Das wäre sehr mühsam und Sie haben vielleicht nicht die Zeit, viele Kombinationen auszuprobieren. Stattdessen sollten Sie Scikit-Learn's **GridSearchCV** für die Suche nach geeigneten Hyperparametern einsetzen. Sie brauchen der Funktion nur zu sagen, mit welchen Hyperparametern sie experimentieren soll und welche Werte ausprobiert werden wollen. GridSearchCV wird dann alle möglichen Kombinationen von Hyperparameterwerten unter Verwendung von Kreuzvalidierung bewerten. Der folgende Code sucht z.B. nach der besten Kombination von Hyperparameterwerten für den RandomForestRegressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Array mit allen Paramtern, die im Rahmen des Trainings verändert werden sollen\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30],'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "scoring='neg_mean_squared_error')\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "# Ausgabe der besten Paramter:\n",
    "grid_search.best_params_\n",
    "\n",
    "grid_search.best_estimator_\n",
    "\n",
    "# Alle Scores der Leistungsmessungen\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch GridSearchCV werden unterschiedliche Paramter für den RandomForest-Algorithmus ausprobiert. Im ersten Schritt werden alle Kombinationen aus n_estimators und max_features (12 Kombinationen) ausprobiert. In einem zweiten Durchgang werden dann nochmal ohne bootstrapping zwei n_estiamtors mit drei max_features ausprobiert. Zusätzlich wird 5-fache Crossvalidierung ausprobiert. In Summe werden also 12+6 = 18 Kombinationen in 5 facher Cross-Validierung ausprobiert. Das macht in Summe 90 Trainingsrunden, um die besten Paramter zu ermitteln. Das dauert seine Zeit und sollte nur auf einem leistungsstarken Rechner oder über Nacht ausgeführt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zufällige Suche\n",
    "Der Ansatz der Rastersuche (GridSearchCV) ist in Ordnung, wenn Sie relativ wenige Kombinationen ausprobieren,\n",
    "wie im vorherigen Beispiel. Aber wenn der Hyperparameter-Suchraum groß ist, sollte man stattdessen **RandomizedSearchCV** verwenden. Diese Klasse arbeitet auf die gleiche Weise wie die Klasse GridSearchCV, aber anstatt alle möglichen Kombinationen auszuprobiere, bewertet sie eine bestimmte Anzahl von Zufallskombinationen durch Auswahl von zufälligen Werten für jeden Hyperparameter bei jeder Iteration. Dieser Ansatz hat zwei Hauptvorteile: \n",
    "- Wenn Sie die randomisierte Suche z.B. über 1.000 Iterationen laufen lassen, wird dieser Ansatz 1.000 verschiedene Werte für jeden Hyperparameter untersuchen (statt nur ein paar Werte pro Hyperparameter mit dem Grid-Search-Ansatz).\n",
    "- Sie haben mehr Kontrolle über das Rechenbudget, das Sie den Hyperparametern zuweisen wollen. Sie können einfach die Anzahl der Iterationen festlegen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation des Modells auf dem Testdatensatz\n",
    "Nachdem Sie eine Zeit lang an Ihren Modellen gefeilt haben, verfügen Sie letztlich über ein Modell, das ausreichend gut funktioniert. Jetzt ist es an der Zeit, das endgültige Modell auf dem Testset zu evaluieren. Es gibt nichts Besonderes an diesem Prozess; holen Sie einfach die Prädiktoren und die Labels aus Ihrem Testsatz, führen Sie Ihre Datentransformationspipeline (full_pipeline) aus, um die Daten zu transformieren (rufen Sie transform() auf, nicht fit_transform()!), und evaluieren Sie das endgültige Modell auf dem Testsatz. Der folgende Code ist aus Performance-gründen im Notebook nicht in vertretbarer Zeit ausführbar. Es gibt aber eine separate Übungsaufgabe zu Mashine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#Hohle das Modell mit den besten Hyperparametern\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "#Trenne den Testdatensatz in Faktoren (x) und Labels (y)\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "#Transforamtion der Testdaten (z.B. Behandlung von kategoriellen Werten)\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "# Vorhersageberechnung\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "# Bewertung der Leistungsfähigkeit bzw. Prognosegüte des Modells\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
